{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "camembert_embeddings.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "2TLgua1UZ9eg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "outputId": "172268a6-72c4-441f-91b9-e69594e34599"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%cd 'drive/My Drive/projet-info/'"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n",
            "/content/drive/My Drive/projet-info\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HnNdCToxoKA_",
        "colab_type": "code",
        "outputId": "4b14479f-d8c7-4cb4-a89d-5d40d40143c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 434
        }
      },
      "source": [
        "# Download necessary additional libraries\n",
        "!pip install unidecode\n",
        "!pip install transformers"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: unidecode in /usr/local/lib/python3.6/dist-packages (1.1.1)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (2.7.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.38.0)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.38)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.21.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: tokenizers==0.5.2 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.5.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.2)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.12.33)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (from transformers) (0.1.85)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.14.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.1)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.8)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2019.11.28)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: botocore<1.16.0,>=1.15.33 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (1.15.33)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.3.3)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.9.5)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.33->boto3->transformers) (2.8.1)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.33->boto3->transformers) (0.15.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZJFT0vWkondj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from multiprocessing import cpu_count\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn as nn\n",
        "from transformers import AutoModel, AutoTokenizer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0OE6F58RAl7g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Number of available cores for parallel computing\n",
        "N_CORES = cpu_count()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_nwp7FVQrVw4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class TokenizeForBERT(Dataset):\n",
        "    \"\"\"Convert corpus to tensors of token indices in a BERT model vocabulary.\"\"\"\n",
        "    def __init__(self, corpus, model_name='camembert-base', maxlen=None):\n",
        "        self.corpus = corpus\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "        if maxlen == None:\n",
        "            self.maxlen = 512 # Max doc length allowed by BERT models\n",
        "        else:\n",
        "            self.maxlen = maxlen\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.corpus)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "\n",
        "        # Select instance\n",
        "        sentence = self.corpus[index]\n",
        "\n",
        "        # Preprocess data as required by BERT models\n",
        "        tokens = self.tokenizer.tokenize(sentence)\n",
        "        bos_token = self.tokenizer.cls_token\n",
        "        eos_token = self.tokenizer.sep_token\n",
        "        pad_token = self.tokenizer.pad_token\n",
        "        # Insert CLS and SEP tokens at beginning and end of sentence\n",
        "        tokens = [bos_token] + tokens + [eos_token]\n",
        "        if len(tokens) < self.maxlen:\n",
        "            # If sentence is shorter than maxlen, pad sentence using special \n",
        "            # padding token\n",
        "            tokens = tokens + [pad_token for _ in range(self.maxlen - len(tokens))]\n",
        "        else:\n",
        "            # Cut the sentence if it is longer than maxlen\n",
        "            tokens = tokens[:self.maxlen-1] + [eos_token]\n",
        "\n",
        "        # Convert tokens to tensor of indices in BERT model vocabulary\n",
        "        tokens_ids = self.tokenizer.convert_tokens_to_ids(tokens)\n",
        "        tokens_ids_tensor = torch.tensor(tokens_ids)\n",
        "        # Get attention mask to distinguish padding tokens from actual tokens\n",
        "        pad_token_id = self.tokenizer.convert_tokens_to_ids(pad_token)\n",
        "        attn_mask = (tokens_ids_tensor != pad_token_id).long()\n",
        "\n",
        "        return tokens_ids_tensor, attn_mask"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8cF51xpwq9zj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def compute_representations(corpus, model_name='camembert-base', batch_size=256,\n",
        "                            max_tokens=None, gpu=True):\n",
        "    \"\"\"Compute representations of employment offers using a BERT model.\"\"\"\n",
        "\n",
        "    # Tokenize documents as needed for BERT models\n",
        "    tokenized_corpus = TokenizeForBERT(corpus=corpus, model_name=model_name,\n",
        "                                       maxlen=max_tokens)\n",
        "    # Prepare data in batches (for RAM issues)\n",
        "    corpus_loader = DataLoader(tokenized_corpus, batch_size=batch_size, \n",
        "                               num_workers=N_CORES)\n",
        "    # Load BERT model\n",
        "    model = AutoModel.from_pretrained(model_name)\n",
        "\n",
        "    # Send model to GPU for (much) faster computations\n",
        "    if gpu:\n",
        "        model = model.to(\"cuda\")\n",
        "\n",
        "    batches_rep = []\n",
        "    for it, (seq, attn_masks) in enumerate(corpus_loader):\n",
        "\n",
        "        if gpu:\n",
        "            seq, attn_masks = seq.cuda(), attn_masks.cuda()\n",
        "\n",
        "        # Compute document representations without constructing the computing \n",
        "        # graph (only needed for backprop)\n",
        "        with torch.no_grad():\n",
        "            cont_reps, _ = model(seq, attention_mask=attn_masks)\n",
        "        # Get representation of [CLS] head (document representation)\n",
        "        cls_rep = cont_reps[:, 0]\n",
        "        # Store representations of current batch as a numpy array\n",
        "        batches_rep.append(cls_rep.cpu().numpy())\n",
        "\n",
        "    return np.vstack(batches_rep)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r1kPX9Lr4TfP",
        "colab_type": "code",
        "outputId": "3f92476b-bdb3-4c4b-96d0-80375fb7da71",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        }
      },
      "source": [
        "# Download employment offers\n",
        "!wget https://raw.githubusercontent.com/avouacr/3A-ENSAE-projet-info/master/API_test/df_max_pages.csv"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-04-05 17:25:15--  https://raw.githubusercontent.com/avouacr/3A-ENSAE-projet-info/master/API_test/df_max_pages.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2647301 (2.5M) [text/plain]\n",
            "Saving to: ‘df_max_pages.csv.28’\n",
            "\n",
            "\rdf_max_pages.csv.28   0%[                    ]       0  --.-KB/s               \rdf_max_pages.csv.28 100%[===================>]   2.52M  --.-KB/s    in 0.04s   \n",
            "\n",
            "2020-04-05 17:25:15 (60.8 MB/s) - ‘df_max_pages.csv.28’ saved [2647301/2647301]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L4nIqg_W4Xeb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import employment offers\n",
        "df_offers = pd.read_csv('df_max_pages.csv')\n",
        "descriptions = df_offers['description'].values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zcd2dveYCSAu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "d41c7568-aad9-41c1-c749-45f9e616c768"
      },
      "source": [
        "%%time\n",
        "\n",
        "# Compute BERT representations of employment offers\n",
        "corpus_representations = compute_representations(corpus=descriptions, \n",
        "                                                 model_name='camembert-base', \n",
        "                                                 batch_size=256, max_tokens=None,\n",
        "                                                 gpu=True)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 49.8 s, sys: 32.1 s, total: 1min 21s\n",
            "Wall time: 1min 23s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ms2cxuBbLV5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = AutoModel.from_pretrained('camembert-base')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k60FalQhYWd3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Safety check\n",
        "assert corpus_representations.shape[0] == len(descriptions)\n",
        "assert corpus_representations.shape[1] == 768"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3eE7m1BOY4HQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Store representations\n",
        "np.savetxt('camembert_representations.txt', corpus_representations)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "df2U9n3FbumC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}